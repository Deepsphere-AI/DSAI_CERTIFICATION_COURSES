{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Designing & Implementing data pipelines for a Customer Sentiment Usecase.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Problem Statement**"],"metadata":{"id":"u1zJ1xe7WBvJ"}},{"cell_type":"markdown","source":["\n","Recent studies show that patients started looking into online ratings and reviews for selecting their physicians and they find these online reviews very reliable. These online reviews are an excellent resource for the patients as well as for the healthcare organization to maintain their reputation. \n","By monitoring online reviews and conducting a sentimental analysis, we can quickly and effectively identify negative reviews as these negative reviews play a major impact online and might bring down the reputation of the organization."],"metadata":{"id":"csI87BVwWFwJ"}},{"cell_type":"code","source":["import pandas as pd\n","from google.colab import drive  \n","from sklearn.preprocessing import LabelEncoder"],"metadata":{"id":"ef3rHJKFWgl-","executionInfo":{"status":"ok","timestamp":1650882428161,"user_tz":-330,"elapsed":339,"user":{"displayName":"workshop Deepsphere","userId":"04217694769501581834"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class Data_pipline_Customer_Sentiment:\n","  def __init__(self):\n","    self.path = ''\n","\n","# Step 1: Data Collection\n","\n","  def read_data_from_drive(self):\n","    drive.mount('/content/drive',force_remount=True)\n","    !mkdir temp\n","    !cp -av '/content/drive/MyDrive/Data Engineering/Intermediate/Unit-3/Source Data/Customer Sentiment.csv' '/content/drive/MyDrive/Data Engineering/Intermediate/Unit-3/temp/Customer Sentiment.csv'\n","    self.Customer_Sentiment = '/content/drive/MyDrive/Data Engineering/Intermediate/Unit-3/temp/Customer Sentiment.csv'\n","\n","  def print_collected_data(self):\n","    self.vAR_df = pd.read_csv(self.Customer_Sentiment)\n","    #print(self.vAR_df.head)\n","    #return self.vAR_df\n","\n","# Step 2: Data Preparation \n","\n","# The Data Preparation Steps Involves a lot of steps including Data Integration,\n","# data Mapping, data Transformation, Removing Duplicates, Missing Values etc. Here in this\n","# example we are implementing only sum of them\n","\n","\n","  def convert_String_to_numerical(self):\n","    self.vAR_df1 =  self.vAR_df[['inbound']] \n","    self.vAR_le = LabelEncoder()\n","    self.vAR_inbound_Conversion = self.vAR_le.fit_transform(self.vAR_df['inbound'])\n","    self.vAR_inbound_Conversion_df = pd.DataFrame(self.vAR_inbound_Conversion,columns={'inbound_Converted'})\n","    self.vAR_created_at_Conversion = self.vAR_le.fit_transform(self.vAR_df['created_at'])\n","    self.vAR_created_at_Convertion_df = pd.DataFrame(self.vAR_created_at_Conversion,columns={'created_at_Converted'})\n","    self.vAR_text_Conversion = self.vAR_le.fit_transform(self.vAR_df['text'])\n","    self.vAR_text_Convertion_df = pd.DataFrame(self.vAR_text_Conversion,columns={'text_Converted'})\n","\n","  def merge_to_orginal_df(self):\n","    self.vAR_inbound_Conversion = pd.DataFrame(self.vAR_inbound_Conversion)\n","    self.vAR_df2 = self.vAR_df.merge(self.vAR_inbound_Conversion_df, left_index=True, right_index=True)\n","    self.vAR_df3 = self.vAR_df2.merge(self.vAR_created_at_Convertion_df, left_index=True, right_index=True)\n","    self.vAR_df4 = self.vAR_df3.merge(self.vAR_text_Convertion_df, left_index=True, right_index=True)\n","    return self.vAR_df2.columns\n","\n","  def Add_Encoded_column(self):\n","    self.vAR_df5 = self.vAR_df4[['tweet_id', 'author_id', 'inbound_Converted', 'created_at_Converted','response_tweet_id', 'in_response_to_tweet_id','text_Converted' ]]\n","    #return self.vAR_df5.head()\n","\n","  def Missing_value(self):\n","    self.mean_value1=self.vAR_df5['in_response_to_tweet_id'].mean() \n","    self.vAR_df6 = self.vAR_df5['in_response_to_tweet_id'].fillna(value=self.mean_value1, inplace=True)\n","    print(self.vAR_df6)\n","\n","   # Step 3: Data Provisioning \n","  def Training_Test_data(self):\n","    vAR_X = self.vAR_df6.iloc[:,0:5]\n","    vAR_y = self.vAR_df6.iloc[:,6] \n","    \n","    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(vAR_X, vAR_y, test_size=0.2, \n","                                                        random_state=42, shuffle=True)\n","    print(self.X_train)\n","    print(self.y_train)\n","\n","vAR_obj = Data_pipline_Customer_Sentiment()\n","vAR_obj.read_data_from_drive()\n","vAR_obj.print_collected_data()\n","vAR_obj.convert_String_to_numerical()\n","vAR_obj.merge_to_orginal_df()\n","vAR_obj.Add_Encoded_column()\n","vAR_obj.Missing_value()\n","#vAR_obj.Training_Test_data()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yUY8Y_pUWdtf","outputId":"9cbc5bc2-4c7f-4cac-9a5d-80df9b7aeaf8","executionInfo":{"status":"ok","timestamp":1650885075516,"user_tz":-330,"elapsed":3912,"user":{"displayName":"workshop Deepsphere","userId":"04217694769501581834"}}},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","mkdir: cannot create directory ‘temp’: File exists\n","'/content/drive/MyDrive/Data Engineering/Intermediate/Unit-3/Source Data/Customer Sentiment.csv' -> '/content/drive/MyDrive/Data Engineering/Intermediate/Unit-3/temp/Customer Sentiment.csv'\n","None\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:6392: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  return self._update_inplace(result)\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"XKIM448MAfNG"},"execution_count":null,"outputs":[]}]}